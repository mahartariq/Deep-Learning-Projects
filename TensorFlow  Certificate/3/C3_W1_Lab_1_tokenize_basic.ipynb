{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C3_W1_Lab_1_tokenize_basic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BZSlp3DAjdYf"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkVZSkIyQIQX"
      },
      "source": [
        "**Note:** This notebook can run using TensorFlow 2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdVrYNXHQIQX"
      },
      "source": [
        "#!pip install tensorflow==2.5.0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaCMcjMQifQc",
        "outputId": "7efe0054-ee8a-4bda-eb18-967f5aac2c18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentences = [\n",
        "    'i love my dog',\n",
        "    'I, love my cat',\n",
        "    'You love my dog!','Amazon SageMaker provides a suite of built-in algorithms to help data scientists and machine learning practitioners get started on training and deploying machine learning models quickly. For someone that is new to SageMaker, choosing the right algorithm for your particular use case can be a challenging task. The following table provides a quick cheat sheet that shows how you can start with an example problem or use case and find an appropriate built-in algorithm offered by SageMaker that is valid for that problem type. '\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'that': 1, 'love': 2, 'my': 3, 'sagemaker': 4, 'a': 5, 'and': 6, 'for': 7, 'i': 8, 'dog': 9, 'you': 10, 'provides': 11, 'built': 12, 'in': 13, 'to': 14, 'machine': 15, 'learning': 16, 'is': 17, 'the': 18, 'algorithm': 19, 'use': 20, 'case': 21, 'can': 22, 'an': 23, 'problem': 24, 'cat': 25, 'amazon': 26, 'suite': 27, 'of': 28, 'algorithms': 29, 'help': 30, 'data': 31, 'scientists': 32, 'practitioners': 33, 'get': 34, 'started': 35, 'on': 36, 'training': 37, 'deploying': 38, 'models': 39, 'quickly': 40, 'someone': 41, 'new': 42, 'choosing': 43, 'right': 44, 'your': 45, 'particular': 46, 'be': 47, 'challenging': 48, 'task': 49, 'following': 50, 'table': 51, 'quick': 52, 'cheat': 53, 'sheet': 54, 'shows': 55, 'how': 56, 'start': 57, 'with': 58, 'example': 59, 'or': 60, 'find': 61, 'appropriate': 62, 'offered': 63, 'by': 64, 'valid': 65, 'type': 66}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X_9I5fXQIQY"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}